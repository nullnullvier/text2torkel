from flask import Flask, request, jsonify, Response, abort, render_template
from markupsafe import escape
from flask_limiter import Limiter
from piper.voice import PiperVoice
import numpy as np
import sounddevice as sd
import logging
import re
import os
import random
import hashlib
from scipy.io.wavfile import write

logging.basicConfig(level=logging.INFO)

# Settings for the HTTP Endpoint
app = Flask(__name__, template_folder='../dist', static_folder='../dist/assets')
limiter = Limiter(
    key_func=lambda: request.headers.get('X-Real-IP', request.remote_addr),  # Use X-Real-IP or fallback to remote_addr
    app=app,
    default_limits=["7200 per day", "300 per hour", "5 per minute"]
)
max_text_length_input: int = 500

# Setting for the voice model
model_folder = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'data/models')
config_path = model_folder + "/kantodel.onnx.json"
voice = PiperVoice.load(model_folder + "/kantodel.onnx", config_path=config_path)

def convert_text_to_speech(text: str) -> str:
  filtered_text: str = filter_text(text)
  filled_text: str = add_filler_words(filtered_text);  
  # sample_rate from the voice model (it shout be 22050)
  sample_rate = voice.config.sample_rate
  logging.debug("sample_rate: " + str(sample_rate))  
 
  return output_sound(wav_file_path="no file provided", filled_text=filled_text)

def convert_text_to_speech_with_save_as_wav(text: str) -> str:
  filtered_text: str = filter_text(text)
  filled_text: str = add_filler_words(filtered_text)
  
  sample_rate = voice.config.sample_rate
  logging.debug("sample_rate: " + str(sample_rate))
  
  # Ensure the filename is valid
  file_name:str = hashlib.md5(b"" + filled_text.encode('utf-8')).hexdigest()
  wav_file_path = "../bot/wav/" + f"{file_name}.wav"
  logging.debug("Text: " + filled_text)
  logging.debug("wav file: " + file_name)
  
  # Initialize a buffer to collect audio data
  audio_buffer = []

  # Synthesize audio and save it to buffer
  for audio_bytes in voice.synthesize_stream_raw(filled_text):
      int_data = np.frombuffer(audio_bytes, dtype=np.int16)
      audio_buffer.append(int_data)
  
  # Combine all audio data into a single numpy array
  audio_data = np.concatenate(audio_buffer)

  # Save the audio data to a .wav file
  write(wav_file_path, 22050, audio_data)
  save_path = os.path.abspath(wav_file_path)
  logging.info(f"Audio saved to {save_path}")

  # Play audio using sounddevice   
  return output_sound(wav_file_path=save_path, filled_text=filled_text)

# output the sound on the soundcard
@staticmethod
def output_sound(wav_file_path: str, filled_text: str) -> str:
  logging.info("output_sound called with path: " + wav_file_path + " and text: " + filled_text)
  try:
    # hint:
    # sampleRate is fix for the voice model 
    # channels 1 (mono) 2 (stereo)
    #
    # Setup a sounddevice OutputStream with appropriate parameters
    # sudo apt-get install libportaudio2
    out_stream = sd.OutputStream(samplerate=22050, channels=1, dtype='int16')
    out_stream.start()

    for audio_bytes in voice.synthesize_stream_raw(filled_text):
      int_data = np.frombuffer(audio_bytes, dtype=np.int16)
      out_stream.write(int_data)

    out_stream.stop()
    out_stream.close()

    return wav_file_path
  
  except sd.PortAudioError as e:
    logging.error("output error: "+str(e))

    return wav_file_path

# remove all non german letter of the given text
@staticmethod
def filter_text(text: str) -> str:
  filtered_text = re.sub('[^A-Za-z0-9äöüÄÖÜß ]+', ' ', text)

  return filtered_text

# adding word to fill/make the output it more human like
@staticmethod
def add_filler_words(text: str) -> str:
  words: list[str] = re.split('\s+', text)
  fill_words: list[str] = ["ahh", "um", "uff", "hmm", "mhh", "mh","mhhhhhh", "uff", "ähh", "ähh ", ".  ", "ä ", " ", "  " ]
  temp_list: list[str] = []
  for idx, word in enumerate(words):
    if idx % 3 == 0 and bool(random.getrandbits(1)) == True:
      temp_list.append(random.choice(fill_words))
    temp_list.append(word)
  
  return ' '.join(temp_list)    

# Display the template that get generated by react
# Example:
# http://127.0.0.1:8080/
@app.route('/')
def index() -> str:
  logging.info("Contents of current folder: %s", os.listdir(model_folder))
  
  return render_template('index.html')

# simple HTTP ENDPOINT for bots
# Example:
# http://127.0.0.1:8080/bot?text=blablabla
@limiter.limit("10 per minute")
@app.route('/bot', methods=['GET'])
def bot() -> Response:
  logging.debug("bot call")

  text = request.args.get('text', default = '', type = str)

  if len(text) > max_text_length_input:
    logging.error("Data to long")
    abort(400)

  escape_text: str = escape(text)
  logging.info("data -- " + escape_text)

  results = convert_text_to_speech_with_save_as_wav(escape_text)
  
  return jsonify(results)


# Main Endpoint as HTTP POST for the human UI 
# Example:
# http://127.0.0.1:8080/api/
@limiter.limit("5 per minute")
@app.route('/api', methods=['POST'])
def local() -> Response:
  logging.debug("api called")
  content_type = request.headers.get('Content-Type')

  if content_type != 'application/json':
    logging.error("not a JSON in the header")
    abort(400)

  if not request.is_json:
    logging.error("not a json as payload")
    abort(400)

  text: str = request.json.get('text')
  if text is None:
    logging.error("Please input a valid string")
    abort(400)
    
  if len(text) > max_text_length_input:
    logging.error("Data to long")
    abort(400)

  escape_text: str = escape(text)

  logging.info("data -- " + escape_text)

  results = convert_text_to_speech(escape_text)
  json_results = jsonify(results)
  logging.info("response json: " + str(json_results))

  return json_results
